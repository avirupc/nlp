{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SUIL6GFGcyr"
      },
      "source": [
        "# Transformers, what can they do?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJg0x--HGcys"
      },
      "source": [
        "Install the Transformers, Datasets, and Evaluate libraries to run this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jrkwpozMGcyt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in d:\\avirup\\nlp\\projects\\nlp\\lib\\site-packages (4.4.1)\n",
            "Requirement already satisfied: evaluate in d:\\avirup\\nlp\\projects\\nlp\\lib\\site-packages (0.4.6)\n",
            "Requirement already satisfied: transformers[sentencepiece] in d:\\avirup\\nlp\\projects\\nlp\\lib\\site-packages (4.57.3)\n",
            "Requirement already satisfied: filelock in d:\\avirup\\nlp\\projects\\nlp\\lib\\site-packages (from datasets) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in d:\\avirup\\nlp\\projects\\nlp\\lib\\site-packages (from datasets) (2.3.4)\n",
            "Requirement already satisfied: pyarrow>=21.0.0 in d:\\avirup\\nlp\\projects\\nlp\\lib\\site-packages (from datasets) (22.0.0)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in d:\\avirup\\nlp\\projects\\nlp\\lib\\site-packages (from datasets) (0.4.0)\n",
            "Requirement already satisfied: pandas in d:\\avirup\\nlp\\projects\\nlp\\lib\\site-packages (from datasets) (2.3.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in d:\\avirup\\nlp\\projects\\nlp\\lib\\site-packages (from datasets) (2.32.5)\n",
            "Requirement already satisfied: httpx<1.0.0 in d:\\avirup\\nlp\\projects\\nlp\\lib\\site-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in d:\\avirup\\nlp\\projects\\nlp\\lib\\site-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in d:\\avirup\\nlp\\projects\\nlp\\lib\\site-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.19 in d:\\avirup\\nlp\\projects\\nlp\\lib\\site-packages (from datasets) (0.70.18)\n",
            "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in d:\\avirup\\nlp\\projects\\nlp\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in d:\\avirup\\nlp\\projects\\nlp\\lib\\site-packages (from datasets) (0.36.0)\n",
            "Requirement already satisfied: packaging in d:\\avirup\\nlp\\projects\\nlp\\lib\\site-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in d:\\avirup\\nlp\\projects\\nlp\\lib\\site-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in d:\\avirup\\nlp\\projects\\nlp\\lib\\site-packages (from transformers[sentencepiece]) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in d:\\avirup\\nlp\\projects\\nlp\\lib\\site-packages (from transformers[sentencepiece]) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in d:\\avirup\\nlp\\projects\\nlp\\lib\\site-packages (from transformers[sentencepiece]) (0.7.0)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in d:\\avirup\\nlp\\projects\\nlp\\lib\\site-packages (from transformers[sentencepiece]) (0.2.1)\n",
            "Requirement already satisfied: protobuf in d:\\avirup\\nlp\\projects\\nlp\\lib\\site-packages (from transformers[sentencepiece]) (6.33.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in d:\\avirup\\nlp\\projects\\nlp\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: anyio in d:\\avirup\\nlp\\projects\\nlp\\lib\\site-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
            "Requirement already satisfied: certifi in d:\\avirup\\nlp\\projects\\nlp\\lib\\site-packages (from httpx<1.0.0->datasets) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in d:\\avirup\\nlp\\projects\\nlp\\lib\\site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
            "Requirement already satisfied: idna in d:\\avirup\\nlp\\projects\\nlp\\lib\\site-packages (from httpx<1.0.0->datasets) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in d:\\avirup\\nlp\\projects\\nlp\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\avirup\\nlp\\projects\\nlp\\lib\\site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\avirup\\nlp\\projects\\nlp\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\avirup\\nlp\\projects\\nlp\\lib\\site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: colorama in d:\\avirup\\nlp\\projects\\nlp\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\avirup\\nlp\\projects\\nlp\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in d:\\avirup\\nlp\\projects\\nlp\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in d:\\avirup\\nlp\\projects\\nlp\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in d:\\avirup\\nlp\\projects\\nlp\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in d:\\avirup\\nlp\\projects\\nlp\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in d:\\avirup\\nlp\\projects\\nlp\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in d:\\avirup\\nlp\\projects\\nlp\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\avirup\\nlp\\projects\\nlp\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in d:\\avirup\\nlp\\projects\\nlp\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\avirup\\nlp\\projects\\nlp\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in d:\\avirup\\nlp\\projects\\nlp\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in d:\\avirup\\nlp\\projects\\nlp\\lib\\site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.3.1 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "! pip install datasets evaluate transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XvIz9md1Gcyt",
        "outputId": "9a378682-421d-42af-c3bd-dc819359bf73"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
            "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m classifier = \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msentiment-analysis\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Avirup\\NLP\\Projects\\nlp\\Lib\\site-packages\\transformers\\pipelines\\__init__.py:1017\u001b[39m, in \u001b[36mpipeline\u001b[39m\u001b[34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[39m\n\u001b[32m   1012\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1013\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mYou cannot use both `pipeline(... dtype=..., model_kwargs=\u001b[39m\u001b[33m{\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m:...})` as those\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1014\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m arguments might conflict, use only one.)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1015\u001b[39m         )\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1017\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[43mtorch\u001b[49m, dtype):\n\u001b[32m   1018\u001b[39m         dtype = \u001b[38;5;28mgetattr\u001b[39m(torch, dtype)\n\u001b[32m   1019\u001b[39m     model_kwargs[\u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m] = dtype\n",
            "\u001b[31mNameError\u001b[39m: name 'torch' is not defined"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Package                   Version\n",
            "------------------------- -----------\n",
            "aiohappyeyeballs          2.6.1\n",
            "aiohttp                   3.13.2\n",
            "aiosignal                 1.4.0\n",
            "anyio                     4.11.0\n",
            "argon2-cffi               25.1.0\n",
            "argon2-cffi-bindings      25.1.0\n",
            "arrow                     1.4.0\n",
            "asttokens                 3.0.0\n",
            "async-lru                 2.0.5\n",
            "attrs                     25.4.0\n",
            "babel                     2.17.0\n",
            "beautifulsoup4            4.14.2\n",
            "black                     25.9.0\n",
            "bleach                    6.3.0\n",
            "certifi                   2025.10.5\n",
            "cffi                      2.0.0\n",
            "charset-normalizer        3.4.4\n",
            "click                     8.3.0\n",
            "colorama                  0.4.6\n",
            "comm                      0.2.3\n",
            "contourpy                 1.3.3\n",
            "cycler                    0.12.1\n",
            "datasets                  4.4.1\n",
            "debugpy                   1.8.17\n",
            "decorator                 5.2.1\n",
            "defusedxml                0.7.1\n",
            "dill                      0.4.0\n",
            "evaluate                  0.4.6\n",
            "executing                 2.2.1\n",
            "fastjsonschema            2.21.2\n",
            "filelock                  3.20.0\n",
            "fonttools                 4.60.1\n",
            "fqdn                      1.5.1\n",
            "frozenlist                1.8.0\n",
            "fsspec                    2025.10.0\n",
            "gensim                    4.4.0\n",
            "h11                       0.16.0\n",
            "httpcore                  1.0.9\n",
            "httpx                     0.28.1\n",
            "huggingface-hub           0.36.0\n",
            "idna                      3.11\n",
            "ipykernel                 7.1.0\n",
            "ipython                   9.7.0\n",
            "ipython_pygments_lexers   1.1.1\n",
            "ipywidgets                8.1.8\n",
            "isoduration               20.11.0\n",
            "jedi                      0.19.2\n",
            "Jinja2                    3.1.6\n",
            "joblib                    1.5.2\n",
            "json5                     0.12.1\n",
            "jsonpointer               3.0.0\n",
            "jsonschema                4.25.1\n",
            "jsonschema-specifications 2025.9.1\n",
            "jupyter                   1.1.1\n",
            "jupyter_client            8.6.3\n",
            "jupyter-console           6.6.3\n",
            "jupyter_core              5.9.1\n",
            "jupyter-events            0.12.0\n",
            "jupyter-lsp               2.3.0\n",
            "jupyter_server            2.17.0\n",
            "jupyter_server_terminals  0.5.3\n",
            "jupyterlab                4.4.10\n",
            "jupyterlab_pygments       0.3.0\n",
            "jupyterlab_server         2.28.0\n",
            "jupyterlab_widgets        3.0.16\n",
            "kiwisolver                1.4.9\n",
            "lark                      1.3.1\n",
            "MarkupSafe                3.0.3\n",
            "matplotlib                3.10.7\n",
            "matplotlib-inline         0.2.1\n",
            "mistune                   3.1.4\n",
            "multidict                 6.7.0\n",
            "multiprocess              0.70.18\n",
            "mypy_extensions           1.1.0\n",
            "nbclient                  0.10.2\n",
            "nbconvert                 7.16.6\n",
            "nbformat                  5.10.4\n",
            "nest-asyncio              1.6.0\n",
            "nltk                      3.9.2\n",
            "notebook                  7.4.7\n",
            "notebook_shim             0.2.4\n",
            "numpy                     2.3.4\n",
            "packaging                 25.0\n",
            "pandas                    2.3.3\n",
            "pandocfilters             1.5.1\n",
            "parso                     0.8.5\n",
            "pathspec                  0.12.1\n",
            "pillow                    12.0.0\n",
            "pip                       24.3.1\n",
            "platformdirs              4.5.0\n",
            "prometheus_client         0.23.1\n",
            "prompt_toolkit            3.0.52\n",
            "propcache                 0.4.1\n",
            "protobuf                  6.33.2\n",
            "psutil                    7.1.3\n",
            "pure_eval                 0.2.3\n",
            "pyarrow                   22.0.0\n",
            "pycparser                 2.23\n",
            "Pygments                  2.19.2\n",
            "pyparsing                 3.2.5\n",
            "python-dateutil           2.9.0.post0\n",
            "python-json-logger        4.0.0\n",
            "pytokens                  0.3.0\n",
            "pytz                      2025.2\n",
            "pywinpty                  3.0.2\n",
            "PyYAML                    6.0.3\n",
            "pyzmq                     27.1.0\n",
            "referencing               0.37.0\n",
            "regex                     2025.11.3\n",
            "requests                  2.32.5\n",
            "rfc3339-validator         0.1.4\n",
            "rfc3986-validator         0.1.1\n",
            "rfc3987-syntax            1.1.0\n",
            "rpds-py                   0.28.0\n",
            "safetensors               0.7.0\n",
            "scikit-learn              1.7.2\n",
            "scipy                     1.16.3\n",
            "seaborn                   0.13.2\n",
            "Send2Trash                1.8.3\n",
            "sentencepiece             0.2.1\n",
            "setuptools                80.9.0\n",
            "six                       1.17.0\n",
            "smart_open                7.4.4\n",
            "sniffio                   1.3.1\n",
            "soupsieve                 2.8\n",
            "stack-data                0.6.3\n",
            "terminado                 0.18.1\n",
            "threadpoolctl             3.6.0\n",
            "tinycss2                  1.4.0\n",
            "tokenizers                0.22.1\n",
            "tornado                   6.5.2\n",
            "tqdm                      4.67.1\n",
            "traitlets                 5.14.3\n",
            "transformers              4.57.3\n",
            "typing_extensions         4.15.0\n",
            "tzdata                    2025.2\n",
            "uri-template              1.3.0\n",
            "urllib3                   2.5.0\n",
            "wcwidth                   0.2.14\n",
            "webcolors                 25.10.0\n",
            "webencodings              0.5.1\n",
            "websocket-client          1.9.0\n",
            "widgetsnbextension        4.0.15\n",
            "wrapt                     2.0.1\n",
            "xxhash                    3.6.0\n",
            "yarl                      1.22.0\n"
          ]
        }
      ],
      "source": [
        "! pip list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjNYXn1dGcyu",
        "outputId": "1861415f-44ef-462d-c99c-9dd44c628e85"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9598047137260437},\n",
              " {'label': 'NEGATIVE', 'score': 0.9994558095932007}]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier(\n",
        "    [\"I've been waiting for a HuggingFace course my whole life.\", \"I hate this so much!\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rH-N1rcmGcyu",
        "outputId": "98a2ba7f-c096-4aa2-8d42-6db154bcfac7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'sequence': 'This is a course about the Transformers library',\n",
              " 'labels': ['education', 'business', 'politics'],\n",
              " 'scores': [0.8445963859558105, 0.111976258456707, 0.043427448719739914]}"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"zero-shot-classification\")\n",
        "classifier(\n",
        "    \"This is a course about the Transformers library\",\n",
        "    candidate_labels=[\"education\", \"politics\", \"business\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34XXbS2NGcyv",
        "outputId": "7eb5af76-7f75-4c39-f435-1420ac1cd7e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'generated_text': 'In this course, we will teach you how to understand and use '\n",
              "                    'data flow and data interchange when handling user data. We '\n",
              "                    'will be working with one or more of the most commonly used '\n",
              "                    'data flows â€” data flows of various types, as seen by the '\n",
              "                    'HTTP'}]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\")\n",
        "generator(\"In this course, we will teach you how to\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFVZeR7EGcyv",
        "outputId": "6602578d-267b-445e-f1a8-0b2259d154d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'generated_text': 'In this course, we will teach you how to manipulate the world and '\n",
              "                    'move your mental and physical capabilities to your advantage.'},\n",
              " {'generated_text': 'In this course, we will teach you how to become an expert and '\n",
              "                    'practice realtime, and with a hands on experience on both real '\n",
              "                    'time and real'}]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
        "generator(\n",
        "    \"In this course, we will teach you how to\",\n",
        "    max_length=30,\n",
        "    num_return_sequences=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57seyYDYGcyw",
        "outputId": "5c33f803-4790-4f00-8425-4bee7e28268b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'sequence': 'This course will teach you all about mathematical models.',\n",
              "  'score': 0.19619831442832947,\n",
              "  'token': 30412,\n",
              "  'token_str': ' mathematical'},\n",
              " {'sequence': 'This course will teach you all about computational models.',\n",
              "  'score': 0.04052725434303284,\n",
              "  'token': 38163,\n",
              "  'token_str': ' computational'}]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "unmasker = pipeline(\"fill-mask\")\n",
        "unmasker(\"This course will teach you all about <mask> models.\", top_k=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_cjBKEQGcyx",
        "outputId": "8a1a80f3-78ea-42d6-ba4c-8a28cebf7497"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'entity_group': 'PER', 'score': 0.99816, 'word': 'Sylvain', 'start': 11, 'end': 18}, \n",
              " {'entity_group': 'ORG', 'score': 0.97960, 'word': 'Hugging Face', 'start': 33, 'end': 45}, \n",
              " {'entity_group': 'LOC', 'score': 0.99321, 'word': 'Brooklyn', 'start': 49, 'end': 57}\n",
              "]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "ner = pipeline(\"ner\", grouped_entities=True)\n",
        "ner(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcIa1MpeGcyx",
        "outputId": "d5f32b1a-8d61-4be9-c8cb-ae71db39273c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'score': 0.6385916471481323, 'start': 33, 'end': 45, 'answer': 'Hugging Face'}"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "question_answerer = pipeline(\"question-answering\")\n",
        "question_answerer(\n",
        "    question=\"Where do I work?\",\n",
        "    context=\"My name is Sylvain and I work at Hugging Face in Brooklyn\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uB-djm9nGcyy",
        "outputId": "a5bb86c6-82c4-4147-898d-29ccecac2871"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'summary_text': ' America has changed dramatically during recent years . The '\n",
              "                  'number of engineering graduates in the U.S. has declined in '\n",
              "                  'traditional engineering disciplines such as mechanical, civil '\n",
              "                  ', electrical, chemical, and aeronautical engineering . Rapidly '\n",
              "                  'developing economies such as China and India, as well as other '\n",
              "                  'industrial countries in Europe and Asia, continue to encourage '\n",
              "                  'and advance engineering .'}]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\")\n",
        "summarizer(\n",
        "    \"\"\"\n",
        "    America has changed dramatically during recent years. Not only has the number of\n",
        "    graduates in traditional engineering disciplines such as mechanical, civil,\n",
        "    electrical, chemical, and aeronautical engineering declined, but in most of\n",
        "    the premier American universities engineering curricula now concentrate on\n",
        "    and encourage largely the study of engineering science. As a result, there\n",
        "    are declining offerings in engineering subjects dealing with infrastructure,\n",
        "    the environment, and related issues, and greater concentration on high\n",
        "    technology subjects, largely supporting increasingly complex scientific\n",
        "    developments. While the latter is important, it should not be at the expense\n",
        "    of more traditional engineering.\n",
        "\n",
        "    Rapidly developing economies such as China and India, as well as other\n",
        "    industrial countries in Europe and Asia, continue to encourage and advance\n",
        "    the teaching of engineering. Both China and India, respectively, graduate\n",
        "    six and eight times as many traditional engineers as does the United States.\n",
        "    Other industrial countries at minimum maintain their output, while America\n",
        "    suffers an increasingly serious decline in the number of engineering graduates\n",
        "    and a lack of well-educated engineers.\n",
        "\"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6_XfD7vGcyy",
        "outputId": "0f67ba10-f1a5-4986-9888-131cd5beec9d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'translation_text': 'This course is produced by Hugging Face.'}]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-fr-en\")\n",
        "translator(\"Ce cours est produit par Hugging Face.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Transformers, what can they do?",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "nlp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
